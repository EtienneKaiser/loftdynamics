{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import functions\n",
    "reload(functions)\n",
    "from functions import get_flight_ids, load_json_file,load_parquet_file,process_json_file,  process_parquet_file, remove_constant_columns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Split Train-Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['08412468-26ac-4777-9afb-4671f426277b', '0b3f3902-2c04-4625-8576-3bb963e3d709', '0bbf0c4e-fb3c-4213-bff8-ef21ee5ebf79', '1675a16e-a2a3-4038-9007-50b0b26a685c', '21194a58-8a4d-4d0f-a4a9-e374393183b4', '28bd3cd3-1d6a-403f-ab8a-83efaf260dd0', '2a2467dd-9cb2-45de-a64f-f182395b3d1a', '39b2c145-c49f-470b-8280-d253fa98153f', '663f573a-74c5-4368-b60b-1fb433cd835d', '8ac99efe-b70b-4b4b-983b-6064fe37c67b', '8c36586f-94e9-4ae9-8384-0f3342008677', '92b2d28b-21e4-498c-b6dd-c27a47716a25', '9a2e5b24-1d93-47ef-bd90-0fae0d719df7', 'a366ff0e-ac1e-4632-821f-594ee8750b90', 'a376807a-82d3-4526-b19f-98d4b3f9078b', 'b5a540db-434b-4c3d-86dd-4668d40586c2', 'd76bb0eb-bc08-4b35-8c1f-37369452083d', 'ef4852a4-fcfe-429b-b753-d11e2ad08cac', 'f40f71de-5cc2-4719-8a5a-abcf950cbd71']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data' \n",
    "flight_ids = get_flight_ids(data_dir)\n",
    "flight_ids.remove('StateDescriptions')\n",
    "print(flight_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = [\n",
    "    \"0b3f3902-2c04-4625-8576-3bb963e3d709\",\n",
    "    \"663f573a-74c5-4368-b60b-1fb433cd835d\",\n",
    "    \"8c36586f-94e9-4ae9-8384-0f3342008677\",\n",
    "    \"a376807a-82d3-4526-b19f-98d4b3f9078b\",\n",
    "    \"d76bb0eb-bc08-4b35-8c1f-37369452083d\",\n",
    "    \"f40f71de-5cc2-4719-8a5a-abcf950cbd71\"\n",
    "]\n",
    "\n",
    "#put the rest into train_ids first\n",
    "train_ids = []\n",
    "for i in flight_ids:\n",
    "    if i not in test_ids:\n",
    "        train_ids.append(i)\n",
    "\n",
    "#split train_ids into train and validation ids\n",
    "\n",
    "train_ids = [\n",
    "    '08412468-26ac-4777-9afb-4671f426277b', \n",
    "    '0bbf0c4e-fb3c-4213-bff8-ef21ee5ebf79', \n",
    "    '1675a16e-a2a3-4038-9007-50b0b26a685c', \n",
    "    '21194a58-8a4d-4d0f-a4a9-e374393183b4', \n",
    "    '28bd3cd3-1d6a-403f-ab8a-83efaf260dd0', \n",
    "    '2a2467dd-9cb2-45de-a64f-f182395b3d1a', \n",
    "    '39b2c145-c49f-470b-8280-d253fa98153f', \n",
    "    '8ac99efe-b70b-4b4b-983b-6064fe37c67b', \n",
    "    '92b2d28b-21e4-498c-b6dd-c27a47716a25',\n",
    "    '9a2e5b24-1d93-47ef-bd90-0fae0d719df7'\n",
    "    ]\n",
    "\n",
    "validate_ids=[\n",
    "    'a366ff0e-ac1e-4632-821f-594ee8750b90',\n",
    "    'b5a540db-434b-4c3d-86dd-4668d40586c2', \n",
    "    'ef4852a4-fcfe-429b-b753-d11e2ad08cac'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train Data Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Process and save the json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 08412468-26ac-4777-9afb-4671f426277b data to train_data/08412468-26ac-4777-9afb-4671f426277b.csv\n",
      "Saved 0bbf0c4e-fb3c-4213-bff8-ef21ee5ebf79 data to train_data/0bbf0c4e-fb3c-4213-bff8-ef21ee5ebf79.csv\n",
      "Saved 1675a16e-a2a3-4038-9007-50b0b26a685c data to train_data/1675a16e-a2a3-4038-9007-50b0b26a685c.csv\n",
      "Saved 21194a58-8a4d-4d0f-a4a9-e374393183b4 data to train_data/21194a58-8a4d-4d0f-a4a9-e374393183b4.csv\n",
      "Saved 28bd3cd3-1d6a-403f-ab8a-83efaf260dd0 data to train_data/28bd3cd3-1d6a-403f-ab8a-83efaf260dd0.csv\n",
      "Saved 2a2467dd-9cb2-45de-a64f-f182395b3d1a data to train_data/2a2467dd-9cb2-45de-a64f-f182395b3d1a.csv\n",
      "Saved 39b2c145-c49f-470b-8280-d253fa98153f data to train_data/39b2c145-c49f-470b-8280-d253fa98153f.csv\n",
      "Saved 8ac99efe-b70b-4b4b-983b-6064fe37c67b data to train_data/8ac99efe-b70b-4b4b-983b-6064fe37c67b.csv\n",
      "Saved 92b2d28b-21e4-498c-b6dd-c27a47716a25 data to train_data/92b2d28b-21e4-498c-b6dd-c27a47716a25.csv\n",
      "Saved 9a2e5b24-1d93-47ef-bd90-0fae0d719df7 data to train_data/9a2e5b24-1d93-47ef-bd90-0fae0d719df7.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data'\n",
    "output_dir = 'train_data'\n",
    "\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "def save_json_data(flight_id):\n",
    "    json_path = os.path.join(data_dir, f\"{flight_id}.json\")\n",
    "\n",
    "    df = load_json_file(json_path)\n",
    "    \n",
    "    df = process_json_file(df)\n",
    "    \n",
    "    output_path = os.path.join(output_dir, f\"{flight_id}.csv\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved {flight_id} data to {output_path}\")\n",
    "\n",
    "for flight_id in train_ids:\n",
    "    save_json_data(flight_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached data to ./cache/train_data/08412468-26ac-4777-9afb-4671f426277b_json.joblib\n",
      "Cached data to ./cache/train_data/0bbf0c4e-fb3c-4213-bff8-ef21ee5ebf79_json.joblib\n",
      "Cached data to ./cache/train_data/1675a16e-a2a3-4038-9007-50b0b26a685c_json.joblib\n",
      "Cached data to ./cache/train_data/21194a58-8a4d-4d0f-a4a9-e374393183b4_json.joblib\n",
      "Cached data to ./cache/train_data/28bd3cd3-1d6a-403f-ab8a-83efaf260dd0_json.joblib\n",
      "Cached data to ./cache/train_data/2a2467dd-9cb2-45de-a64f-f182395b3d1a_json.joblib\n",
      "Cached data to ./cache/train_data/39b2c145-c49f-470b-8280-d253fa98153f_json.joblib\n",
      "Cached data to ./cache/train_data/8ac99efe-b70b-4b4b-983b-6064fe37c67b_json.joblib\n",
      "Cached data to ./cache/train_data/92b2d28b-21e4-498c-b6dd-c27a47716a25_json.joblib\n",
      "Cached data to ./cache/train_data/9a2e5b24-1d93-47ef-bd90-0fae0d719df7_json.joblib\n"
     ]
    }
   ],
   "source": [
    "# cache the processed json file\n",
    "cache_dir = './cache/train_data'  \n",
    "os.makedirs(cache_dir, exist_ok=True) \n",
    "\n",
    "# cache parquet_csv file\n",
    "for flight_id in train_ids:\n",
    "    file_path = os.path.join('./train_data', f\"{flight_id}.csv\")\n",
    "\n",
    "    cache_file = os.path.join(cache_dir, os.path.basename(file_path).replace('.csv', '_json.joblib'))\n",
    "    \n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"{cache_file} cached already\")\n",
    "    else:\n",
    "        data = pd.read_csv(file_path)\n",
    "        dump(data, cache_file)\n",
    "        print(f\"Cached data to {cache_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Analyze StateDescriptions\n",
    "Before we deal with the parquet files, first we have to analyze the StateDescription.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_state_descriptions(json_path):\n",
    "    # Load JSON file\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Flatten JSON data and create a DataFrame\n",
    "    records = []\n",
    "    for name, entry in data.items():\n",
    "        record = {\n",
    "            'Name': name,\n",
    "            'DataType': entry.get('dataType', 'Unknown'),\n",
    "            'Unit': entry.get('unit', 'Unknown'),\n",
    "            'StateID': entry.get('stateId', 'Unknown'),\n",
    "            'Persistence': entry.get('isPersistent', False),\n",
    "        }\n",
    "        \n",
    "        # Add default values for different models\n",
    "        for model, default_value in entry.get('DefaultValues', {}).items():\n",
    "            record[f'Default_{model}'] = default_value\n",
    "\n",
    "        # Add display units for different models\n",
    "        for model, display_unit in entry.get('DefaultDisplayUnits', {}).items():\n",
    "            record[f'Unit_{model}'] = display_unit\n",
    "\n",
    "        records.append(record)\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # Display general information about the DataFrame\n",
    "    print(\"General Info:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    # Display summary statistics for each column\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(df.describe(include='all'))\n",
    "    \n",
    "    # Count unique data types and their frequency\n",
    "    print(\"\\nData Type Counts:\")\n",
    "    print(df['DataType'].value_counts())\n",
    "    \n",
    "    # Count unique units and their frequency\n",
    "    print(\"\\nUnit Counts:\")\n",
    "    print(df['Unit'].value_counts())\n",
    "    \n",
    "    # Check persistence flag distribution\n",
    "    print(\"\\nPersistence Flag Distribution:\")\n",
    "    print(df['Persistence'].value_counts())\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1746 entries, 0 to 1745\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Name         1746 non-null   object\n",
      " 1   DataType     1746 non-null   object\n",
      " 2   Unit         381 non-null    object\n",
      " 3   StateID      1746 non-null   int64 \n",
      " 4   Persistence  1746 non-null   bool  \n",
      "dtypes: bool(1), int64(1), object(3)\n",
      "memory usage: 56.4+ KB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "                       Name DataType Unit       StateID Persistence\n",
      "count                  1746     1746  381  1.746000e+03        1746\n",
      "unique                 1746        8   22           NaN           2\n",
      "top     AddOn_CockpitConfig   Double  0-1           NaN       False\n",
      "freq                      1     1162   99           NaN        1424\n",
      "mean                    NaN      NaN  NaN  2.118100e+09         NaN\n",
      "std                     NaN      NaN  NaN  1.232422e+09         NaN\n",
      "min                     NaN      NaN  NaN  3.513755e+06         NaN\n",
      "25%                     NaN      NaN  NaN  1.048420e+09         NaN\n",
      "50%                     NaN      NaN  NaN  2.131877e+09         NaN\n",
      "75%                     NaN      NaN  NaN  3.186254e+09         NaN\n",
      "max                     NaN      NaN  NaN  4.294954e+09         NaN\n",
      "\n",
      "Data Type Counts:\n",
      "DataType\n",
      "Double     1162\n",
      "Boolean     463\n",
      "Int32        51\n",
      "Double3      32\n",
      "String       18\n",
      "Double2      13\n",
      "Double5       4\n",
      "Double4       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unit Counts:\n",
      "Unit\n",
      "0-1           99\n",
      "m             72\n",
      "kg            46\n",
      "m/s           30\n",
      "rad           26\n",
      "no-value      21\n",
      "s             16\n",
      "Pa            15\n",
      "K             14\n",
      "visibility    12\n",
      "A              5\n",
      "rad/s          4\n",
      "Hz             4\n",
      "mm             3\n",
      "°C             3\n",
      "V              3\n",
      "m/s²           2\n",
      "%              2\n",
      "fraction       1\n",
      "kg/s           1\n",
      "fps            1\n",
      "°              1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Persistence Flag Distribution:\n",
      "Persistence\n",
      "False    1424\n",
      "True      322\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data saved to ./state_descriptions_analysis.csv\n",
      "\n",
      "First few rows of the data:\n",
      "                                    Name DataType  Unit     StateID  \\\n",
      "0                    AddOn_CockpitConfig   String  None  1514024368   \n",
      "1  Aerofly_Out_Aircraft_PressureAltitude   Double     m  2546226082   \n",
      "2            Aerofly_In_Aircraft_Options   String  None  1011097368   \n",
      "3           Aerofly_In_Aircraft_Painting   String  None   115676304   \n",
      "4         Aerofly_In_Aircraft_WindShearX   Double  None  1359970420   \n",
      "\n",
      "   Persistence  \n",
      "0        False  \n",
      "1        False  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "json_path = './data/StateDescriptions.json'\n",
    "df_states = analyze_state_descriptions(json_path)\n",
    "\n",
    "# save to file\n",
    "output_path = './state_descriptions_analysis.csv'\n",
    "df_states.to_csv(output_path, index=False)\n",
    "print(f\"\\nData saved to {output_path}\")\n",
    "\n",
    "# Display the first few rows for inspection\n",
    "print(\"\\nFirst few rows of the data:\")\n",
    "print(df_states.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Process and save parquet data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Cache parquet raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cache/raw/08412468-26ac-4777-9afb-4671f426277b.joblib cached already\n",
      "./cache/raw/0b3f3902-2c04-4625-8576-3bb963e3d709.joblib cached already\n",
      "./cache/raw/0bbf0c4e-fb3c-4213-bff8-ef21ee5ebf79.joblib cached already\n",
      "./cache/raw/1675a16e-a2a3-4038-9007-50b0b26a685c.joblib cached already\n",
      "./cache/raw/21194a58-8a4d-4d0f-a4a9-e374393183b4.joblib cached already\n",
      "./cache/raw/28bd3cd3-1d6a-403f-ab8a-83efaf260dd0.joblib cached already\n",
      "./cache/raw/2a2467dd-9cb2-45de-a64f-f182395b3d1a.joblib cached already\n",
      "./cache/raw/39b2c145-c49f-470b-8280-d253fa98153f.joblib cached already\n",
      "./cache/raw/663f573a-74c5-4368-b60b-1fb433cd835d.joblib cached already\n",
      "./cache/raw/8ac99efe-b70b-4b4b-983b-6064fe37c67b.joblib cached already\n",
      "./cache/raw/8c36586f-94e9-4ae9-8384-0f3342008677.joblib cached already\n",
      "./cache/raw/92b2d28b-21e4-498c-b6dd-c27a47716a25.joblib cached already\n",
      "./cache/raw/9a2e5b24-1d93-47ef-bd90-0fae0d719df7.joblib cached already\n",
      "./cache/raw/a366ff0e-ac1e-4632-821f-594ee8750b90.joblib cached already\n",
      "./cache/raw/a376807a-82d3-4526-b19f-98d4b3f9078b.joblib cached already\n",
      "./cache/raw/b5a540db-434b-4c3d-86dd-4668d40586c2.joblib cached already\n",
      "./cache/raw/d76bb0eb-bc08-4b35-8c1f-37369452083d.joblib cached already\n",
      "./cache/raw/ef4852a4-fcfe-429b-b753-d11e2ad08cac.joblib cached already\n",
      "./cache/raw/f40f71de-5cc2-4719-8a5a-abcf950cbd71.joblib cached already\n"
     ]
    }
   ],
   "source": [
    "cache_dir = './cache/raw'  \n",
    "os.makedirs(cache_dir, exist_ok=True) \n",
    "\n",
    "# cache parquet_csv file\n",
    "for flight_id in flight_ids:\n",
    "    file_path = os.path.join('./data', f\"{flight_id}.parquet\")\n",
    "\n",
    "    cache_file = os.path.join(cache_dir, os.path.basename(file_path).replace('.parquet', '.joblib'))\n",
    "    \n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"{cache_file} cached already\")\n",
    "    else:\n",
    "        data = pd.read_parquet(file_path)\n",
    "        dump(data, cache_file)\n",
    "        print(f\"Cached data to {cache_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 process parquet data and cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.1 See the structures to adjust the function \"process_parquet_file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeStamp                         FrameCounter\n",
      "2024-02-14 06:26:55.328843+00:00  0               0.0\n",
      "2024-02-14 06:26:55.338647+00:00  1               NaN\n",
      "2024-02-14 06:26:57.816582+00:00  2               NaN\n",
      "2024-02-14 06:26:57.831172+00:00  3               NaN\n",
      "2024-02-14 06:26:57.859734+00:00  4               NaN\n",
      "                                                 ... \n",
      "2024-02-14 06:45:40.456558+00:00  289727          NaN\n",
      "2024-02-14 06:45:40.469469+00:00  289728          NaN\n",
      "2024-02-14 06:45:40.488957+00:00  289729          NaN\n",
      "2024-02-14 06:45:40.502970+00:00  289730          NaN\n",
      "2024-02-14 06:45:40.510829+00:00  289731          NaN\n",
      "Name: 3501046967, Length: 205635, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# see the original structure os the parquet file\n",
    "data = pd.read_parquet('./data/2a2467dd-9cb2-45de-a64f-f182395b3d1a.parquet')\n",
    "print(data[3501046967])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                    6417134     \\\n",
      "TimeStamp                        FrameCounter                                                    \n",
      "2024-02-14 06:46:58.397576+00:00 0             [1.0, 0.17888563049853373, 0.19257086999022482]   \n",
      "2024-02-14 06:46:58.416348+00:00 1             [1.0, 0.17888563049853373, 0.19257086999022482]   \n",
      "2024-02-14 06:47:00.886922+00:00 2             [1.0, 0.17888563049853373, 0.19257086999022482]   \n",
      "2024-02-14 06:47:00.894921+00:00 3             [1.0, 0.17888563049853373, 0.19257086999022482]   \n",
      "2024-02-14 06:47:00.926924+00:00 4             [1.0, 0.17888563049853373, 0.19257086999022482]   \n",
      "\n",
      "                                               6741304     28827303    \\\n",
      "TimeStamp                        FrameCounter                           \n",
      "2024-02-14 06:46:58.397576+00:00 0                  False         0.0   \n",
      "2024-02-14 06:46:58.416348+00:00 1                  False         0.0   \n",
      "2024-02-14 06:47:00.886922+00:00 2                  False         0.0   \n",
      "2024-02-14 06:47:00.894921+00:00 3                  False         0.0   \n",
      "2024-02-14 06:47:00.926924+00:00 4                  False         0.0   \n",
      "\n",
      "                                               32976648    43103889    \\\n",
      "TimeStamp                        FrameCounter                           \n",
      "2024-02-14 06:46:58.397576+00:00 0                  False       False   \n",
      "2024-02-14 06:46:58.416348+00:00 1                  False       False   \n",
      "2024-02-14 06:47:00.886922+00:00 2                  False       False   \n",
      "2024-02-14 06:47:00.894921+00:00 3                  False       False   \n",
      "2024-02-14 06:47:00.926924+00:00 4                  False       False   \n",
      "\n",
      "                                               43292983         45268905    \\\n",
      "TimeStamp                        FrameCounter                                \n",
      "2024-02-14 06:46:58.397576+00:00 0                   10.0  [0.0, 0.0, 0.0]   \n",
      "2024-02-14 06:46:58.416348+00:00 1                   10.0  [0.0, 0.0, 0.0]   \n",
      "2024-02-14 06:47:00.886922+00:00 2                   10.0  [0.0, 0.0, 0.0]   \n",
      "2024-02-14 06:47:00.894921+00:00 3                   10.0  [0.0, 0.0, 0.0]   \n",
      "2024-02-14 06:47:00.926924+00:00 4                   10.0  [0.0, 0.0, 0.0]   \n",
      "\n",
      "                                               46966142    55391156    \\\n",
      "TimeStamp                        FrameCounter                           \n",
      "2024-02-14 06:46:58.397576+00:00 0                  False         0.0   \n",
      "2024-02-14 06:46:58.416348+00:00 1                  False         0.0   \n",
      "2024-02-14 06:47:00.886922+00:00 2                  False         0.0   \n",
      "2024-02-14 06:47:00.894921+00:00 3                  False         0.0   \n",
      "2024-02-14 06:47:00.926924+00:00 4                  False         0.0   \n",
      "\n",
      "                                               68054868    ...  4247030081  \\\n",
      "TimeStamp                        FrameCounter              ...               \n",
      "2024-02-14 06:46:58.397576+00:00 0                   True  ...   -2.521325   \n",
      "2024-02-14 06:46:58.416348+00:00 1                   True  ...   -2.521325   \n",
      "2024-02-14 06:47:00.886922+00:00 2                   True  ...   -0.000000   \n",
      "2024-02-14 06:47:00.894921+00:00 3                   True  ...   -0.000000   \n",
      "2024-02-14 06:47:00.926924+00:00 4                   True  ...   -0.000000   \n",
      "\n",
      "                                               4250662552  4261424841  \\\n",
      "TimeStamp                        FrameCounter                           \n",
      "2024-02-14 06:46:58.397576+00:00 0                    0.0        True   \n",
      "2024-02-14 06:46:58.416348+00:00 1                    0.0        True   \n",
      "2024-02-14 06:47:00.886922+00:00 2                    0.0        True   \n",
      "2024-02-14 06:47:00.894921+00:00 3                    0.0        True   \n",
      "2024-02-14 06:47:00.926924+00:00 4                    0.0        True   \n",
      "\n",
      "                                                                                   4264003232  \\\n",
      "TimeStamp                        FrameCounter                                                   \n",
      "2024-02-14 06:46:58.397576+00:00 0             [1.0, 0.9208211143695014, 0.12316715542521994]   \n",
      "2024-02-14 06:46:58.416348+00:00 1             [1.0, 0.9208211143695014, 0.12316715542521994]   \n",
      "2024-02-14 06:47:00.886922+00:00 2             [1.0, 0.9208211143695014, 0.12316715542521994]   \n",
      "2024-02-14 06:47:00.894921+00:00 3             [1.0, 0.9208211143695014, 0.12316715542521994]   \n",
      "2024-02-14 06:47:00.926924+00:00 4             [1.0, 0.9208211143695014, 0.12316715542521994]   \n",
      "\n",
      "                                               4279155387  4281995872  \\\n",
      "TimeStamp                        FrameCounter                           \n",
      "2024-02-14 06:46:58.397576+00:00 0                   True        True   \n",
      "2024-02-14 06:46:58.416348+00:00 1                   True        True   \n",
      "2024-02-14 06:47:00.886922+00:00 2                   True        True   \n",
      "2024-02-14 06:47:00.894921+00:00 3                   True        True   \n",
      "2024-02-14 06:47:00.926924+00:00 4                   True        True   \n",
      "\n",
      "                                               4289640958  4291312414  \\\n",
      "TimeStamp                        FrameCounter                           \n",
      "2024-02-14 06:46:58.397576+00:00 0                   h125         0.0   \n",
      "2024-02-14 06:46:58.416348+00:00 1                   h125         0.0   \n",
      "2024-02-14 06:47:00.886922+00:00 2                   h125         0.0   \n",
      "2024-02-14 06:47:00.894921+00:00 3                   h125         0.0   \n",
      "2024-02-14 06:47:00.926924+00:00 4                   h125         0.0   \n",
      "\n",
      "                                               4294814812  4294953991  \n",
      "TimeStamp                        FrameCounter                          \n",
      "2024-02-14 06:46:58.397576+00:00 0                    0.0         1.0  \n",
      "2024-02-14 06:46:58.416348+00:00 1                    0.0         1.0  \n",
      "2024-02-14 06:47:00.886922+00:00 2                    0.0         1.0  \n",
      "2024-02-14 06:47:00.894921+00:00 3                    0.0         1.0  \n",
      "2024-02-14 06:47:00.926924+00:00 4                    0.0         1.0  \n",
      "\n",
      "[5 rows x 1047 columns]\n"
     ]
    }
   ],
   "source": [
    "# See the structure of the parquet file after process\n",
    "\n",
    "df = load_parquet_file('./data/08412468-26ac-4777-9afb-4671f426277b.parquet')\n",
    "df = process_parquet_file(df)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([('2024-02-14 06:46:58.397576+00:00',      0),\n",
      "            ('2024-02-14 06:46:58.416348+00:00',      1),\n",
      "            ('2024-02-14 06:47:00.886922+00:00',      2),\n",
      "            ('2024-02-14 06:47:00.894921+00:00',      3),\n",
      "            ('2024-02-14 06:47:00.926924+00:00',      4),\n",
      "            ('2024-02-14 06:47:00.946964+00:00',      5),\n",
      "            ('2024-02-14 06:47:00.950532+00:00',      6),\n",
      "            ('2024-02-14 06:47:00.961775+00:00',      7),\n",
      "            ('2024-02-14 06:47:00.978790+00:00',      8),\n",
      "            ('2024-02-14 06:47:00.984390+00:00',      9),\n",
      "            ...\n",
      "            ('2024-02-14 07:03:21.102460+00:00', 253960),\n",
      "            ('2024-02-14 07:03:21.115700+00:00', 253961),\n",
      "            ('2024-02-14 07:03:21.135562+00:00', 253962),\n",
      "            ('2024-02-14 07:03:21.149007+00:00', 253963),\n",
      "            ('2024-02-14 07:03:21.168594+00:00', 253964),\n",
      "            ('2024-02-14 07:03:21.182601+00:00', 253965),\n",
      "            ('2024-02-14 07:03:21.202792+00:00', 253966),\n",
      "            ('2024-02-14 07:03:21.215947+00:00', 253967),\n",
      "            ('2024-02-14 07:03:21.235502+00:00', 253968),\n",
      "            ('2024-02-14 07:03:21.249083+00:00', 253969)],\n",
      "           names=['TimeStamp', 'FrameCounter'], length=180148)\n"
     ]
    }
   ],
   "source": [
    "# See the structure of the parquet file after remove unnecessay columns\n",
    "\n",
    "df= remove_constant_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               117182271   156875280   \\\n",
      "TimeStamp                        FrameCounter                           \n",
      "2024-02-14 06:46:58.397576+00:00 0               2.312171       False   \n",
      "2024-02-14 06:46:58.416348+00:00 1               2.312171       False   \n",
      "2024-02-14 06:47:00.886922+00:00 2               2.309550       False   \n",
      "2024-02-14 06:47:00.894921+00:00 3               2.309550       False   \n",
      "2024-02-14 06:47:00.926924+00:00 4               2.309550       False   \n",
      "\n",
      "                                                353872548   381802901   \\\n",
      "TimeStamp                        FrameCounter                            \n",
      "2024-02-14 06:46:58.397576+00:00 0             135500000.0         1.0   \n",
      "2024-02-14 06:46:58.416348+00:00 1             135500000.0         1.0   \n",
      "2024-02-14 06:47:00.886922+00:00 2             135500000.0         1.0   \n",
      "2024-02-14 06:47:00.894921+00:00 3             135500000.0         1.0   \n",
      "2024-02-14 06:47:00.926924+00:00 4             135500000.0         1.0   \n",
      "\n",
      "                                               513685691   518160218   \\\n",
      "TimeStamp                        FrameCounter                           \n",
      "2024-02-14 06:46:58.397576+00:00 0             509.681743       False   \n",
      "2024-02-14 06:46:58.416348+00:00 1             509.681743       False   \n",
      "2024-02-14 06:47:00.886922+00:00 2             509.950305        True   \n",
      "2024-02-14 06:47:00.894921+00:00 3             509.950305        True   \n",
      "2024-02-14 06:47:00.926924+00:00 4             509.950305        True   \n",
      "\n",
      "                                                                   557098463   \\\n",
      "TimeStamp                        FrameCounter                                   \n",
      "2024-02-14 06:46:58.397576+00:00 0             [0.0, 0.0, 0.7155849933176751]   \n",
      "2024-02-14 06:46:58.416348+00:00 1             [0.0, 0.0, 0.7155849933176751]   \n",
      "2024-02-14 06:47:00.886922+00:00 2             [0.0, 0.0, 0.7155849933176751]   \n",
      "2024-02-14 06:47:00.894921+00:00 3             [0.0, 0.0, 0.7155849933176751]   \n",
      "2024-02-14 06:47:00.926924+00:00 4             [0.0, 0.0, 0.7155849933176751]   \n",
      "\n",
      "                                               614270119   637219977   \\\n",
      "TimeStamp                        FrameCounter                           \n",
      "2024-02-14 06:46:58.397576+00:00 0               0.868611  510.285568   \n",
      "2024-02-14 06:46:58.416348+00:00 1               0.868611  510.285568   \n",
      "2024-02-14 06:47:00.886922+00:00 2               0.000000  510.556384   \n",
      "2024-02-14 06:47:00.894921+00:00 3               0.000000  510.556384   \n",
      "2024-02-14 06:47:00.926924+00:00 4               0.000000  510.556384   \n",
      "\n",
      "                                               638103778   ...  \\\n",
      "TimeStamp                        FrameCounter              ...   \n",
      "2024-02-14 06:46:58.397576+00:00 0               0.000000  ...   \n",
      "2024-02-14 06:46:58.416348+00:00 1               0.000000  ...   \n",
      "2024-02-14 06:47:00.886922+00:00 2              -0.054277  ...   \n",
      "2024-02-14 06:47:00.894921+00:00 3              -0.054280  ...   \n",
      "2024-02-14 06:47:00.926924+00:00 4              -0.028358  ...   \n",
      "\n",
      "                                                                                      3966668421  \\\n",
      "TimeStamp                        FrameCounter                                                      \n",
      "2024-02-14 06:46:58.397576+00:00 0             [0.015397662947448598, 0.2067386366654791, 9.8...   \n",
      "2024-02-14 06:46:58.416348+00:00 1             [0.015397662947448598, 0.2067386366654791, 9.8...   \n",
      "2024-02-14 06:47:00.886922+00:00 2             [-0.11874119838041874, 0.1965263554522556, 9.8...   \n",
      "2024-02-14 06:47:00.894921+00:00 3             [-0.11874081249685053, 0.19652635273154218, 9....   \n",
      "2024-02-14 06:47:00.926924+00:00 4             [-0.11874081249685053, 0.19652635273154218, 9....   \n",
      "\n",
      "                                               3981973171    4021288050  \\\n",
      "TimeStamp                        FrameCounter                             \n",
      "2024-02-14 06:46:58.397576+00:00 0                  400.0  3.857714e+06   \n",
      "2024-02-14 06:46:58.416348+00:00 1                  400.0  3.857714e+06   \n",
      "2024-02-14 06:47:00.886922+00:00 2                  400.0  4.000000e+06   \n",
      "2024-02-14 06:47:00.894921+00:00 3                  400.0  4.000000e+06   \n",
      "2024-02-14 06:47:00.926924+00:00 4                  400.0  4.000000e+06   \n",
      "\n",
      "                                               4054750327  4056189073  \\\n",
      "TimeStamp                        FrameCounter                           \n",
      "2024-02-14 06:46:58.397576+00:00 0             366.964303  284.837069   \n",
      "2024-02-14 06:46:58.416348+00:00 1             366.964303  284.837069   \n",
      "2024-02-14 06:47:00.886922+00:00 2             381.718000  284.835323   \n",
      "2024-02-14 06:47:00.894921+00:00 3             381.718000  284.835323   \n",
      "2024-02-14 06:47:00.926924+00:00 4             399.580000  284.835323   \n",
      "\n",
      "                                                                                      4058842283  \\\n",
      "TimeStamp                        FrameCounter                                                      \n",
      "2024-02-14 06:46:58.397576+00:00 0             [0.9930367276785365, 0.022116936416472353, 0.0...   \n",
      "2024-02-14 06:46:58.416348+00:00 1             [0.9929756894317355, 0.021576050603372268, 0.0...   \n",
      "2024-02-14 06:47:00.886922+00:00 2             [0.992887299721831, 0.0212184179844126, 0.0884...   \n",
      "2024-02-14 06:47:00.894921+00:00 3             [0.992887299721831, 0.0212184179844126, 0.0884...   \n",
      "2024-02-14 06:47:00.926924+00:00 4             [0.992887299721831, 0.0212184179844126, 0.0884...   \n",
      "\n",
      "                                               4066202059   4174711423  \\\n",
      "TimeStamp                        FrameCounter                            \n",
      "2024-02-14 06:46:58.397576+00:00 0               0.048876  125500000.0   \n",
      "2024-02-14 06:46:58.416348+00:00 1               0.048876  125500000.0   \n",
      "2024-02-14 06:47:00.886922+00:00 2               0.947214  125500000.0   \n",
      "2024-02-14 06:47:00.894921+00:00 3               0.947214  125500000.0   \n",
      "2024-02-14 06:47:00.926924+00:00 4               0.948192  125500000.0   \n",
      "\n",
      "                                               4247030081  \\\n",
      "TimeStamp                        FrameCounter               \n",
      "2024-02-14 06:46:58.397576+00:00 0              -2.521325   \n",
      "2024-02-14 06:46:58.416348+00:00 1              -2.521325   \n",
      "2024-02-14 06:47:00.886922+00:00 2              -0.000000   \n",
      "2024-02-14 06:47:00.894921+00:00 3              -0.000000   \n",
      "2024-02-14 06:47:00.926924+00:00 4              -0.000000   \n",
      "\n",
      "                                                                                   4264003232  \n",
      "TimeStamp                        FrameCounter                                                  \n",
      "2024-02-14 06:46:58.397576+00:00 0             [1.0, 0.9208211143695014, 0.12316715542521994]  \n",
      "2024-02-14 06:46:58.416348+00:00 1             [1.0, 0.9208211143695014, 0.12316715542521994]  \n",
      "2024-02-14 06:47:00.886922+00:00 2             [1.0, 0.9208211143695014, 0.12316715542521994]  \n",
      "2024-02-14 06:47:00.894921+00:00 3             [1.0, 0.9208211143695014, 0.12316715542521994]  \n",
      "2024-02-14 06:47:00.926924+00:00 4             [1.0, 0.9208211143695014, 0.12316715542521994]  \n",
      "\n",
      "[5 rows x 97 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.2 (Optional) Here there is some mistake that the files are saved to .csv, but remaining the same with .parquet is better. \n",
    "Since reprocessing it took a lot of time, so I just wrote the next part to transfer from csv to parquet file.\n",
    "If you haven't processed the data, skip this part and next (Convert \"_parquet.csv\" to \".parquet\"), just run the part of \" Load from cache and process parquet data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File test_data/08412468-26ac-4777-9afb-4671f426277b_parquet.csv already exists. Skipping save.\n",
      "File test_data/0bbf0c4e-fb3c-4213-bff8-ef21ee5ebf79_parquet.csv already exists. Skipping save.\n",
      "File test_data/1675a16e-a2a3-4038-9007-50b0b26a685c_parquet.csv already exists. Skipping save.\n",
      "File test_data/21194a58-8a4d-4d0f-a4a9-e374393183b4_parquet.csv already exists. Skipping save.\n",
      "File test_data/28bd3cd3-1d6a-403f-ab8a-83efaf260dd0_parquet.csv already exists. Skipping save.\n",
      "File test_data/2a2467dd-9cb2-45de-a64f-f182395b3d1a_parquet.csv already exists. Skipping save.\n",
      "File test_data/39b2c145-c49f-470b-8280-d253fa98153f_parquet.csv already exists. Skipping save.\n",
      "File test_data/8ac99efe-b70b-4b4b-983b-6064fe37c67b_parquet.csv already exists. Skipping save.\n",
      "Saved 92b2d28b-21e4-498c-b6dd-c27a47716a25 Parquet data to test_data/92b2d28b-21e4-498c-b6dd-c27a47716a25_parquet.csv\n",
      "Saved 92b2d28b-21e4-498c-b6dd-c27a47716a25 Parquet data to test_data/92b2d28b-21e4-498c-b6dd-c27a47716a25_parquet.csv\n",
      "Saved 9a2e5b24-1d93-47ef-bd90-0fae0d719df7 Parquet data to test_data/9a2e5b24-1d93-47ef-bd90-0fae0d719df7_parquet.csv\n",
      "Saved 9a2e5b24-1d93-47ef-bd90-0fae0d719df7 Parquet data to test_data/9a2e5b24-1d93-47ef-bd90-0fae0d719df7_parquet.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data'\n",
    "output_dir = 'test_data'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Function to process and save Parquet file data\n",
    "def save_parquet_data(flight_id):\n",
    "    parquet_path = os.path.join(data_dir, f\"{flight_id}.parquet\")\n",
    "\n",
    "    df = load_parquet_file(parquet_path)\n",
    "     \n",
    "    df = process_parquet_file(df)  \n",
    "\n",
    "    df = remove_constant_columns(df)\n",
    "    \n",
    "    # Define the base output file name\n",
    "    output_path = os.path.join(output_dir, f\"{flight_id}_parquet.csv\")\n",
    "    \n",
    "    # Save the DataFrame as a CSV file\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved {flight_id} Parquet data to {output_path}\")\n",
    "\n",
    "# Process each Parquet file and save it\n",
    "for flight_id in train_ids: \n",
    "    # check if the file exists\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"File {output_path} already exists. Skipping save.\")\n",
    "    else:\n",
    "        save_parquet_data(flight_id)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.3 (Optional) Convert \"_parquet.csv\" to \".parquet\"\n",
    "If you need to process the parquet data, skip this part. Run next part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 92b2d28b-21e4-498c-b6dd-c27a47716a25_parquet.csv to ./train_data/92b2d28b-21e4-498c-b6dd-c27a47716a25.parquet\n",
      "Deleted original file: ./train_data/92b2d28b-21e4-498c-b6dd-c27a47716a25_parquet.csv\n",
      "Converted 0bbf0c4e-fb3c-4213-bff8-ef21ee5ebf79_parquet.csv to ./train_data/0bbf0c4e-fb3c-4213-bff8-ef21ee5ebf79.parquet\n",
      "Deleted original file: ./train_data/0bbf0c4e-fb3c-4213-bff8-ef21ee5ebf79_parquet.csv\n",
      "Converted 8ac99efe-b70b-4b4b-983b-6064fe37c67b_parquet.csv to ./train_data/8ac99efe-b70b-4b4b-983b-6064fe37c67b.parquet\n",
      "Deleted original file: ./train_data/8ac99efe-b70b-4b4b-983b-6064fe37c67b_parquet.csv\n",
      "Converted 28bd3cd3-1d6a-403f-ab8a-83efaf260dd0_parquet.csv to ./train_data/28bd3cd3-1d6a-403f-ab8a-83efaf260dd0.parquet\n",
      "Deleted original file: ./train_data/28bd3cd3-1d6a-403f-ab8a-83efaf260dd0_parquet.csv\n",
      "Converted 2a2467dd-9cb2-45de-a64f-f182395b3d1a_parquet.csv to ./train_data/2a2467dd-9cb2-45de-a64f-f182395b3d1a.parquet\n",
      "Deleted original file: ./train_data/2a2467dd-9cb2-45de-a64f-f182395b3d1a_parquet.csv\n",
      "Converted 1675a16e-a2a3-4038-9007-50b0b26a685c_parquet.csv to ./train_data/1675a16e-a2a3-4038-9007-50b0b26a685c.parquet\n",
      "Deleted original file: ./train_data/1675a16e-a2a3-4038-9007-50b0b26a685c_parquet.csv\n",
      "Converted 08412468-26ac-4777-9afb-4671f426277b_parquet.csv to ./train_data/08412468-26ac-4777-9afb-4671f426277b.parquet\n",
      "Deleted original file: ./train_data/08412468-26ac-4777-9afb-4671f426277b_parquet.csv\n",
      "Converted 39b2c145-c49f-470b-8280-d253fa98153f_parquet.csv to ./train_data/39b2c145-c49f-470b-8280-d253fa98153f.parquet\n",
      "Deleted original file: ./train_data/39b2c145-c49f-470b-8280-d253fa98153f_parquet.csv\n",
      "Converted 9a2e5b24-1d93-47ef-bd90-0fae0d719df7_parquet.csv to ./train_data/9a2e5b24-1d93-47ef-bd90-0fae0d719df7.parquet\n",
      "Deleted original file: ./train_data/9a2e5b24-1d93-47ef-bd90-0fae0d719df7_parquet.csv\n",
      "Converted 21194a58-8a4d-4d0f-a4a9-e374393183b4_parquet.csv to ./train_data/21194a58-8a4d-4d0f-a4a9-e374393183b4.parquet\n",
      "Deleted original file: ./train_data/21194a58-8a4d-4d0f-a4a9-e374393183b4_parquet.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dir = \"./train_data\" \n",
    "output_dir = \"./train_data\" \n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith(\"_parquet.csv\"): \n",
    "        input_path = os.path.join(input_dir, file_name)\n",
    "        output_path = os.path.join(output_dir, file_name.replace(\"_parquet.csv\", \".parquet\"))\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(input_path)\n",
    "            df.to_parquet(output_path, index=False)\n",
    "            print(f\"Converted {file_name} to {output_path}\")\n",
    "            \n",
    "            os.remove(input_path)\n",
    "            print(f\"Deleted original file: {input_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.4 Load from cache and process parquet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './cache/raw'\n",
    "output_dir = 'test_data'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Function to process and save Parquet file data\n",
    "def save_parquet_data(flight_id):\n",
    "    parquet_path = os.path.join(data_dir, f\"{flight_id}.joblib\")\n",
    "\n",
    "    df = load(parquet_path)\n",
    "     \n",
    "    df = process_parquet_file(df)  \n",
    "\n",
    "    df = remove_constant_columns(df)\n",
    "    \n",
    "    # Define the base output file name\n",
    "    output_path = os.path.join(output_dir, f\"{flight_id}.parquet\")\n",
    "    \n",
    "    # Save the DataFrame as a CSV file\n",
    "    df.to_parquet(output_path, index=False)\n",
    "    print(f\"Saved {flight_id} Parquet data to {output_path}\")\n",
    "\n",
    "# Process each Parquet file and save it\n",
    "for flight_id in train_ids:\n",
    "    # check if the file exists\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"File {output_path} already exists. Skipping save.\")\n",
    "    else:\n",
    "        save_parquet_data(flight_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './test_data/08412468-26ac-4777-9afb-4671f426277b_parquet.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[285], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded cached data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# 加载原始文件并缓存\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     dump(data, cache_file)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCached data to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/loftdynamics/lody/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/loftdynamics/lody/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/loftdynamics/lody/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/loftdynamics/lody/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/loftdynamics/lody/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './test_data/08412468-26ac-4777-9afb-4671f426277b_parquet.csv'"
     ]
    }
   ],
   "source": [
    "cache_dir = './cache/train'  \n",
    "os.makedirs(cache_dir, exist_ok=True)  # 如果目录不存在，创建它\n",
    "\n",
    "# cache parquet_csv file\n",
    "for flight_id in train_ids:\n",
    "    file_path = os.path.join('./train_data', f\"{flight_id}_parquet.csv\")\n",
    "\n",
    "    cache_file = os.path.join(cache_dir, os.path.basename(file_path).replace('.csv', '.joblib'))\n",
    "    \n",
    "    if os.path.exists(cache_file):\n",
    "        data = load(cache_file)\n",
    "        print(f\"Loaded cached data from {cache_file}\")\n",
    "    else:\n",
    "        # 加载原始文件并缓存\n",
    "        data = pd.read_csv(file_path)\n",
    "        dump(data, cache_file)\n",
    "        print(f\"Cached data to {cache_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>117182271</th>\n",
       "      <th>156875280</th>\n",
       "      <th>301190512</th>\n",
       "      <th>513685691</th>\n",
       "      <th>518160218</th>\n",
       "      <th>557098463</th>\n",
       "      <th>614270119</th>\n",
       "      <th>637219977</th>\n",
       "      <th>638103778</th>\n",
       "      <th>677695791</th>\n",
       "      <th>...</th>\n",
       "      <th>3966668421</th>\n",
       "      <th>3981973171</th>\n",
       "      <th>4021288050</th>\n",
       "      <th>4054750327</th>\n",
       "      <th>4056189073</th>\n",
       "      <th>4058842283</th>\n",
       "      <th>4061964072</th>\n",
       "      <th>4066202059</th>\n",
       "      <th>4247030081</th>\n",
       "      <th>4294814812</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.161555</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.821214</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.         0.         0.71558499]</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>511.429802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Basic Autorotation</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.2164971   0.10619898  9.80703578]</td>\n",
       "      <td>400.0</td>\n",
       "      <td>4.003269e+06</td>\n",
       "      <td>369.629338</td>\n",
       "      <td>284.829662</td>\n",
       "      <td>[ 0.9999952   0.00244388  0.00148651 -0.00119296]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955034</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.161555</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.821214</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.         0.         0.71558499]</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>511.429802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Basic Autorotation</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.2164971   0.10619898  9.80703578]</td>\n",
       "      <td>400.0</td>\n",
       "      <td>4.003269e+06</td>\n",
       "      <td>369.629338</td>\n",
       "      <td>284.829662</td>\n",
       "      <td>[ 0.99999562  0.0024262   0.00136185 -0.0010058 ]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953079</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.161634</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.910498</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.         0.         0.71558499]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>511.517236</td>\n",
       "      <td>-0.049156</td>\n",
       "      <td>Basic Autorotation</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.14433302  0.10619898  9.80836326]</td>\n",
       "      <td>400.0</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>381.718000</td>\n",
       "      <td>284.829082</td>\n",
       "      <td>[ 9.99996147e-01  2.66921047e-03  6.07066059e-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.161634</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.910498</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.         0.         0.71558499]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>511.517236</td>\n",
       "      <td>-0.051131</td>\n",
       "      <td>Basic Autorotation</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.14433263  0.10619898  9.80836326]</td>\n",
       "      <td>400.0</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>381.718000</td>\n",
       "      <td>284.829082</td>\n",
       "      <td>[ 9.99996147e-01  2.66921047e-03  6.07066059e-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.161634</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.910498</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.         0.         0.71558499]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>511.517236</td>\n",
       "      <td>-0.063683</td>\n",
       "      <td>Basic Autorotation</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.14433263  0.10619898  9.80836326]</td>\n",
       "      <td>400.0</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>399.580000</td>\n",
       "      <td>284.829082</td>\n",
       "      <td>[ 9.99996147e-01  2.66921047e-03  6.07066059e-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   117182271  156875280  301190512   513685691  518160218  \\\n",
       "0   5.161555      False        0.0  510.821214       True   \n",
       "1   5.161555      False        0.0  510.821214       True   \n",
       "2   5.161634      False        0.0  510.910498       True   \n",
       "3   5.161634      False        0.0  510.910498       True   \n",
       "4   5.161634      False        0.0  510.910498       True   \n",
       "\n",
       "                            557098463  614270119   637219977  638103778  \\\n",
       "0  [0.         0.         0.71558499]   0.006515  511.429802   0.000000   \n",
       "1  [0.         0.         0.71558499]   0.006515  511.429802   0.000000   \n",
       "2  [0.         0.         0.71558499]   0.000000  511.517236  -0.049156   \n",
       "3  [0.         0.         0.71558499]   0.000000  511.517236  -0.051131   \n",
       "4  [0.         0.         0.71558499]   0.000000  511.517236  -0.063683   \n",
       "\n",
       "            677695791  ...                             3966668421  3981973171  \\\n",
       "0  Basic Autorotation  ...  [-0.2164971   0.10619898  9.80703578]       400.0   \n",
       "1  Basic Autorotation  ...  [-0.2164971   0.10619898  9.80703578]       400.0   \n",
       "2  Basic Autorotation  ...  [-0.14433302  0.10619898  9.80836326]       400.0   \n",
       "3  Basic Autorotation  ...  [-0.14433263  0.10619898  9.80836326]       400.0   \n",
       "4  Basic Autorotation  ...  [-0.14433263  0.10619898  9.80836326]       400.0   \n",
       "\n",
       "     4021288050  4054750327  4056189073  \\\n",
       "0  4.003269e+06  369.629338  284.829662   \n",
       "1  4.003269e+06  369.629338  284.829662   \n",
       "2  4.000000e+06  381.718000  284.829082   \n",
       "3  4.000000e+06  381.718000  284.829082   \n",
       "4  4.000000e+06  399.580000  284.829082   \n",
       "\n",
       "                                          4058842283  4061964072  4066202059  \\\n",
       "0  [ 0.9999952   0.00244388  0.00148651 -0.00119296]         1.0    0.955034   \n",
       "1  [ 0.99999562  0.0024262   0.00136185 -0.0010058 ]         1.0    0.953079   \n",
       "2  [ 9.99996147e-01  2.66921047e-03  6.07066059e-...         1.0    0.950147   \n",
       "3  [ 9.99996147e-01  2.66921047e-03  6.07066059e-...         1.0    0.950147   \n",
       "4  [ 9.99996147e-01  2.66921047e-03  6.07066059e-...         1.0    0.950147   \n",
       "\n",
       "   4247030081  4294814812  \n",
       "0    0.002615         0.0  \n",
       "1    0.002615         0.0  \n",
       "2    0.000000         0.0  \n",
       "3    0.000000         0.0  \n",
       "4    0.000000         0.0  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test reaading speed\n",
    "\n",
    "data = load('./cache/9a2e5b24-1d93-47ef-bd90-0fae0d719df7_parquet.joblib')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Cache parquet processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached data to ./cache/train_data/08412468-26ac-4777-9afb-4671f426277b_parquet.joblib\n",
      "Cached data to ./cache/train_data/0bbf0c4e-fb3c-4213-bff8-ef21ee5ebf79_parquet.joblib\n",
      "Cached data to ./cache/train_data/1675a16e-a2a3-4038-9007-50b0b26a685c_parquet.joblib\n",
      "Cached data to ./cache/train_data/21194a58-8a4d-4d0f-a4a9-e374393183b4_parquet.joblib\n",
      "Cached data to ./cache/train_data/28bd3cd3-1d6a-403f-ab8a-83efaf260dd0_parquet.joblib\n",
      "Cached data to ./cache/train_data/2a2467dd-9cb2-45de-a64f-f182395b3d1a_parquet.joblib\n",
      "Cached data to ./cache/train_data/39b2c145-c49f-470b-8280-d253fa98153f_parquet.joblib\n",
      "Cached data to ./cache/train_data/8ac99efe-b70b-4b4b-983b-6064fe37c67b_parquet.joblib\n",
      "Cached data to ./cache/train_data/92b2d28b-21e4-498c-b6dd-c27a47716a25_parquet.joblib\n",
      "Cached data to ./cache/train_data/9a2e5b24-1d93-47ef-bd90-0fae0d719df7_parquet.joblib\n"
     ]
    }
   ],
   "source": [
    "cache_dir = './cache/train_data'  \n",
    "os.makedirs(cache_dir, exist_ok=True) \n",
    "\n",
    "# cache parquet_csv file\n",
    "for flight_id in train_ids:\n",
    "    file_path = os.path.join('./train_data', f\"{flight_id}.parquet\")\n",
    "\n",
    "    cache_file = os.path.join(cache_dir, os.path.basename(file_path).replace('.parquet', '_parquet.joblib'))\n",
    "    \n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"{cache_file} cached already\")\n",
    "    else:\n",
    "        data = pd.read_parquet(file_path)\n",
    "        dump(data, cache_file)\n",
    "        print(f\"Cached data to {cache_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualize the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lody",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
